{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Installing and Importing Libraries"
      ],
      "metadata": {
        "id": "K9qWht8eoru_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOdyUWEjXnuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66442607-bb34-47d6-8cc0-b4e1afe4a6b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install annoy"
      ],
      "metadata": {
        "id": "7FrMskwyX36B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ff95f9-03b0-46cf-956d-bb056b34dae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting annoy\n",
            "  Downloading annoy-1.17.1.tar.gz (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.0/648.0 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.1-cp38-cp38-linux_x86_64.whl size=582769 sha256=b178a805f24fc51d5d513ddbdf097d7a5e1b7b66fbb50f9753c2c6d80b7f1a52\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/93/19/30511c4a9ae6b4937455a134c34a39e13943e2c6f46fcd2ed2\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "import pandas as pd\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import numpy as np\n",
        "import annoy"
      ],
      "metadata": {
        "id": "s9e7ifPtX4oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load training dataset\n",
        "def load_data():\n",
        "    CSV_URL = 'https://drive.google.com/u/0/uc?id=1Z-yb752A3o7b9dqrGt24XU0sl53FVqya&export=download'\n",
        "\n",
        "    with requests.Session() as s:\n",
        "        download = s.get(CSV_URL)\n",
        "        decoded_content = download.content.decode('utf-8')\n",
        "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
        "        train_data = list(cr)\n",
        "\n",
        "    print(f\"Number of examples = {len(train_data)}\")\n",
        "    ans, noans = 0, 0\n",
        "    for x in train_data:\n",
        "        if x[4] == 'False':\n",
        "            noans += 1\n",
        "        else:\n",
        "            ans += 1\n",
        "    print(f\"\\tAnswerable questions = {ans}\")\n",
        "    print(f\"\\tNon-Answerable questions = {noans}\\n\")\n",
        "    print(\"Examples:\")\n",
        "    for i in [0, 1000, 1300]:\n",
        "        print(' | '.join(train_data[i][:2]), ' | ', train_data[i][2][:20] + '...', ' | ', ' | '.join(train_data[i][3:]))\n",
        "    return train_data"
      ],
      "metadata": {
        "id": "91QpZpsqX5WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_theme_wise_data(train_data):\n",
        "    theme_wise_data = {}\n",
        "    for x in train_data[1:]:\n",
        "        if x[1] not in theme_wise_data:\n",
        "            theme_wise_data[x[1]] = {\n",
        "                'para': [],\n",
        "                'ques': [],\n",
        "                'ans': []\n",
        "            }\n",
        "        if x[2] not in theme_wise_data[x[1]]['para']:\n",
        "            theme_wise_data[x[1]]['para'].append(x[2])\n",
        "        theme_wise_data[x[1]]['ques'].append(x[3])\n",
        "        # ans contains a list -> [Para_Number, Answer_possible, Answer_text, Answer_start]\n",
        "        theme_wise_data[x[1]]['ans'].append([theme_wise_data[x[1]]['para'].index(x[2])] + x[4:])\n",
        "    print(f'\\nTotal {len(theme_wise_data)} themes present.')\n",
        "    return theme_wise_data"
      ],
      "metadata": {
        "id": "hkzf0BviX8Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
        "model = hub.load(module_url)"
      ],
      "metadata": {
        "id": "FbhGMFeLX9DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = load_data()\n",
        "theme_wise_data = load_theme_wise_data(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDPWiDyeX9n7",
        "outputId": "4da9f68c-3e81-49d5-e960-3eb63e1b23ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples = 75056\n",
            "\tAnswerable questions = 50126\n",
            "\tNon-Answerable questions = 24930\n",
            "\n",
            "Examples:\n",
            " | Theme  |  Paragraph...  |  Question | Answer_possible | Answer_text | Answer_start\n",
            "1430 | Frédéric_Chopin  |  Some modern commenta...  |  Who said Chopin's works were modeled after Bach, Beethoven, Schubert and Field? | True | ['Richard Taruskin'] | [543]\n",
            "2196 | The_Legend_of_Zelda:_Twilight_Princess  |  Twilight Princess ta...  |  Who releases Bulbins from the Realm of Twilight? | False | [] | []\n",
            "\n",
            "Total 361 themes present.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]"
      ],
      "metadata": {
        "id": "U8w4B4dlr2ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theme = 'Adolescence'"
      ],
      "metadata": {
        "id": "Hn88SjX9YFq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1rCktWk6rljttLjiXCupAF0wrS5oHUI8K\n",
        "\n",
        "df = pd.read_csv('Question Generation - Sheet1.csv')\n",
        "query = df[df['Theme']==theme]['Similar Question']\n",
        "actual_ques = df[df['Theme']==theme]['Question']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N54YhN3DppWd",
        "outputId": "8dd5dab1-836e-40b8-9a1b-a32b5fd3c697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rCktWk6rljttLjiXCupAF0wrS5oHUI8K\n",
            "To: /content/Question Generation - Sheet1.csv\n",
            "\r  0% 0.00/13.0k [00:00<?, ?B/s]\r100% 13.0k/13.0k [00:00<00:00, 16.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_ques = list(theme_wise_data[theme]['ques'])\n",
        "t_ans = list(theme_wise_data[theme]['ans'])\n",
        "t_ans = [i[2][2:-2] for i in t_ans]\n",
        "t = [[i, j] for i,j in zip(t_ques , t_ans )]\n",
        "new_t = {idx:[t[idx][0],t[idx][1]] for idx in range(len(t))}"
      ],
      "metadata": {
        "id": "bQCzjVJkYN6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Embeddings and Index for ANNOY Similarity Search"
      ],
      "metadata": {
        "id": "jt3JbV5QqxUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data=model(t_ques)\n",
        "encoded_data = np.array(encoded_data)"
      ],
      "metadata": {
        "id": "xT5ARzcgYQOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index_annoy(embeddings, vector_length = 512, metric = 'angular', num_trees = 100):\n",
        "  annoy_index = annoy.AnnoyIndex(vector_length, metric=metric)\n",
        "  for i in range(len(embeddings)):\n",
        "    annoy_index.add_item(i, embeddings[i])\n",
        "  annoy_index.build(n_trees = num_trees)\n",
        "  return annoy_index"
      ],
      "metadata": {
        "id": "-_pId6Y3YSGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index =create_index_annoy(encoded_data)"
      ],
      "metadata": {
        "id": "c7W8Q8dyYWeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Accuracy Calculation"
      ],
      "metadata": {
        "id": "rO9KbP-yrW4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_annoy(index ,embedding, num_matches=1):\n",
        "  '''Finds similar items to a given embedding in the ANN index'''\n",
        "  \n",
        "  ids = index.get_nns_by_vector(\n",
        "  embedding, num_matches, search_k=-1, include_distances=True)\n",
        "  score = ids[1]\n",
        "  questions = [new_t[id][0] for id in ids[0]]\n",
        "  return [(a[0], a[1]) for a in zip(questions, score)]"
      ],
      "metadata": {
        "id": "-0FY2eUWYX6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_ques(query, index, model, actual_ques):\n",
        "    query_vector = model(query)\n",
        "    query_vector =  query_vector.numpy()\n",
        "    results = find_similar_annoy(index,query_vector[0])\n",
        "    result = results[0][1]\n",
        "    if(result<threshold):\n",
        "      if(results[0][0] == actual_ques[0]):\n",
        "        return 1 #Can be answered from previously answered query\n",
        "      else:\n",
        "        return 0\n",
        "    else:\n",
        "      return 0 #Can\\'t be answered from previously answered query"
      ],
      "metadata": {
        "id": "Sf1bH8hlY9Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(query, index, model, actual_ques):\n",
        "  sum = 0\n",
        "  for i in range(len(query)):\n",
        "    sum += top_k_ques([query[i]], index, model, [actual_ques[i]])\n",
        "\n",
        "  Accuracy = sum/len(query)*100\n",
        "  print('For a threshold = '+ str(threshold) + ', the accuracy comes at ' + str(Accuracy)+' %')"
      ],
      "metadata": {
        "id": "7gsOrWhDsBCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for threshold in thresholds:\n",
        "  accuracy(query, index, model, actual_ques)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1uTM4TrsAFu",
        "outputId": "592e3755-6f7a-4772-ca7c-0727c4ca1c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For a threshold = 0.3, the accuracy comes at 0.0 %\n",
            "For a threshold = 0.35, the accuracy comes at 0.0 %\n",
            "For a threshold = 0.4, the accuracy comes at 6.666666666666667 %\n",
            "For a threshold = 0.45, the accuracy comes at 13.333333333333334 %\n",
            "For a threshold = 0.5, the accuracy comes at 20.0 %\n",
            "For a threshold = 0.55, the accuracy comes at 46.666666666666664 %\n",
            "For a threshold = 0.6, the accuracy comes at 66.66666666666666 %\n",
            "For a threshold = 0.65, the accuracy comes at 86.66666666666667 %\n",
            "For a threshold = 0.7, the accuracy comes at 93.33333333333333 %\n"
          ]
        }
      ]
    }
  ]
}