{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmark for Retro-Reader  \n",
        "This is a benchmark for the retro-reader architecture using ELECTRA Large LM as the baseline. Tests are done with 500 answerable and 500 non answerable questions from our dataset."
      ],
      "metadata": {
        "id": "TxalW83QgTEi"
      },
      "id": "TxalW83QgTEi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependencies"
      ],
      "metadata": {
        "id": "ZCowL-4uhFVe"
      },
      "id": "ZCowL-4uhFVe"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ShivamIITK21/retro-reader.git"
      ],
      "metadata": {
        "id": "oE_O9wOQhRCV"
      },
      "id": "oE_O9wOQhRCV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd retro-reader"
      ],
      "metadata": {
        "id": "HZkaqR5JhSzS"
      },
      "id": "HZkaqR5JhSzS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "import datasets\n",
        "import transformers\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "WdimcTLlhY8v"
      },
      "id": "WdimcTLlhY8v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Model"
      ],
      "metadata": {
        "id": "3siQkCgohqnF"
      },
      "id": "3siQkCgohqnF"
    },
    {
      "cell_type": "code",
      "source": [
        "from retro_reader import constants as C\n",
        "from retro_reader import RetroReader"
      ],
      "metadata": {
        "id": "K_aPG602hwW9"
      },
      "id": "K_aPG602hwW9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_file = \"configs/inference_en_electra_large.yaml\"\n",
        "retro_reader = RetroReader.load(config_file=config_file)"
      ],
      "metadata": {
        "id": "LfTelyQKh3rA"
      },
      "id": "LfTelyQKh3rA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test prediction for understanding IO"
      ],
      "metadata": {
        "id": "-zl7KnA-h_9S"
      },
      "id": "-zl7KnA-h_9S"
    },
    {
      "cell_type": "code",
      "source": [
        "pred_examples = datasets.Dataset.from_pandas(pd.DataFrame(data = [\n",
        "    {\n",
        "        \"example_id\": \"0\",\n",
        "        \"guid\": \"id-01\",\n",
        "        \"question\": \"What is the most popular game on twitch right now?\",\n",
        "        \"context\": \"Valorant is the most popular game on twitch right now.\"\n",
        "    },\n",
        "    {\n",
        "        \"example_id\": \"1\",\n",
        "        \"guid\": \"id-02\",\n",
        "        \"question\": \"Which is the most popular drink brand?\",\n",
        "        \"context\": \"Coca Cola is the most popular drink brand.\"\n",
        "    }\n",
        "]))"
      ],
      "metadata": {
        "id": "61FiGxiFiD03"
      },
      "id": "61FiGxiFiD03",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = retro_reader.inference(pred_examples)"
      ],
      "metadata": {
        "id": "otphqHdUiM4J"
      },
      "id": "otphqHdUiM4J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "EmrQXrBSiToM"
      },
      "id": "EmrQXrBSiToM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "oq8ZN0cXit0H"
      },
      "id": "oq8ZN0cXit0H"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "\n",
        "# load training dataset\n",
        "def load_data():\n",
        "    CSV_URL = 'https://drive.google.com/u/0/uc?id=1Z-yb752A3o7b9dqrGt24XU0sl53FVqya&export=download'\n",
        "\n",
        "    with requests.Session() as s:\n",
        "        download = s.get(CSV_URL)\n",
        "        decoded_content = download.content.decode('utf-8')\n",
        "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
        "        train_data = pd.DataFrame(cr)\n",
        "\n",
        "    # print(f\"Number of examples = {len(train_data)}\")\n",
        "    # ans, noans = 0, 0\n",
        "    # for x in train_data:\n",
        "    #     if x[4] == 'False':\n",
        "    #         noans += 1\n",
        "    #     else:\n",
        "    #         ans += 1\n",
        "    # print(f\"\\tAnswerable questions = {ans}\")\n",
        "    # print(f\"\\tNon-Answerable questions = {noans}\\n\")\n",
        "    # print(\"Examples:\")\n",
        "    # for i in [0, 1000, 1300]:\n",
        "    #     print(train_data[i][1], ' | ', train_data[i][2][:20] + '...', ' | ', ' | '.join(train_data[i][3:]))\n",
        "    return train_data"
      ],
      "metadata": {
        "id": "qsmwi83diyrQ"
      },
      "id": "qsmwi83diyrQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_data()"
      ],
      "metadata": {
        "id": "zEqAnxLDi4RX"
      },
      "id": "zEqAnxLDi4RX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "P8AKMPW7i924"
      },
      "id": "P8AKMPW7i924",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noans = data.loc[data[4] == \"False\"].sample(n = 100)"
      ],
      "metadata": {
        "id": "QqlJpTWwkgnC"
      },
      "id": "QqlJpTWwkgnC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noans"
      ],
      "metadata": {
        "id": "TFZHVzaKoLKc"
      },
      "id": "TFZHVzaKoLKc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "withans = data.loc[data[4] == \"True\"].sample(100)"
      ],
      "metadata": {
        "id": "4JRMep9vpMFJ"
      },
      "id": "4JRMep9vpMFJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "withans"
      ],
      "metadata": {
        "id": "R6aUAZ8ppgxG"
      },
      "id": "R6aUAZ8ppgxG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the data"
      ],
      "metadata": {
        "id": "fzJWFd3kpt36"
      },
      "id": "fzJWFd3kpt36"
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_data(data):\n",
        "  transform = []\n",
        "  i = 0\n",
        "  for index, row in data.iterrows():\n",
        "    i += 1\n",
        "    context = row[2]\n",
        "    question = row[3]\n",
        "    obj = {\n",
        "        \"example_id\": str(i-1),\n",
        "        \"guid\": \"id-\"+str(i),\n",
        "        \"question\": question,\n",
        "        \"context\": context\n",
        "    }\n",
        "    transform.append(obj)\n",
        "  transform = datasets.Dataset.from_pandas(pd.DataFrame(data = transform))\n",
        "  return transform"
      ],
      "metadata": {
        "id": "0W9IpfynpxkX"
      },
      "id": "0W9IpfynpxkX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "withans_processed = transform_data(withans)"
      ],
      "metadata": {
        "id": "6QLcFlY_s9n2"
      },
      "id": "6QLcFlY_s9n2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "withans_processed"
      ],
      "metadata": {
        "id": "zre_ooWwtGWh"
      },
      "id": "zre_ooWwtGWh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noans_processed = transform_data(noans)"
      ],
      "metadata": {
        "id": "ay0z71gAtH92"
      },
      "id": "ay0z71gAtH92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noans_processed"
      ],
      "metadata": {
        "id": "POkWDV_JtOpk"
      },
      "id": "POkWDV_JtOpk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_truth(data):\n",
        "  truths = []\n",
        "  for index, row in data.iterrows():\n",
        "    truth = row[5][2:-2]\n",
        "    truths.append(truth)\n",
        "  return truths"
      ],
      "metadata": {
        "id": "fV8xotXWtQUn"
      },
      "id": "fV8xotXWtQUn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "4MtlXTf8usL3"
      },
      "id": "4MtlXTf8usL3"
    },
    {
      "cell_type": "code",
      "source": [
        "result_withans = retro_reader.inference(withans_processed)"
      ],
      "metadata": {
        "id": "9JlwMRleuv9N"
      },
      "id": "9JlwMRleuv9N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_withans"
      ],
      "metadata": {
        "id": "qNsSsL9Xu4jX"
      },
      "id": "qNsSsL9Xu4jX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truth = get_truth(withans)\n",
        "truth"
      ],
      "metadata": {
        "id": "gFFhaLVUWDuw"
      },
      "id": "gFFhaLVUWDuw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_noans = retro_reader.inference(noans_processed)"
      ],
      "metadata": {
        "id": "js7WtijsX8cA"
      },
      "id": "js7WtijsX8cA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_withans[0]"
      ],
      "metadata": {
        "id": "1jDXQtl1at6G"
      },
      "id": "1jDXQtl1at6G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics"
      ],
      "metadata": {
        "id": "NlxCqCh1yjFu"
      },
      "id": "NlxCqCh1yjFu"
    },
    {
      "cell_type": "code",
      "source": [
        "import string, re, json, ast\n",
        "\n",
        "def normalize_text(s):\n",
        "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = normalize_text(prediction).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)"
      ],
      "metadata": {
        "id": "6Gxn5yQ9ylt5"
      },
      "id": "6Gxn5yQ9ylt5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_withans[0][\"id-1\"]\n"
      ],
      "metadata": {
        "id": "y-_3zmGCWXbn"
      },
      "id": "y-_3zmGCWXbn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(truth)"
      ],
      "metadata": {
        "id": "D_FFNGmzWoL1"
      },
      "id": "D_FFNGmzWoL1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computef1_batch_withans(result, truth):\n",
        "  f1_sum = 0\n",
        "  for i in range(0, len(truth)):\n",
        "    t = truth[i]\n",
        "    pred = result[0][\"id-\" + str(i+1)]\n",
        "    f1_sum += compute_f1(pred, t)\n",
        "  return f1_sum/len(truth)"
      ],
      "metadata": {
        "id": "Ke_Q3JS1y5SU"
      },
      "id": "Ke_Q3JS1y5SU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "computef1_batch_withans(result_withans, truth)"
      ],
      "metadata": {
        "id": "uqjOjp18XNPF"
      },
      "id": "uqjOjp18XNPF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computef1_batch_noans(result):\n",
        "  f1_sum = 0\n",
        "  for i in range(0, 100):\n",
        "    t = \"\"\n",
        "    pred = result[0][\"id-\" + str(i+1)]\n",
        "    f1_sum += compute_f1(pred, t)\n",
        "  return f1_sum/100"
      ],
      "metadata": {
        "id": "-XCotGuTXVcG"
      },
      "id": "-XCotGuTXVcG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "computef1_batch_noans(result_noans)"
      ],
      "metadata": {
        "id": "xiNyjP7-a1bP"
      },
      "id": "xiNyjP7-a1bP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X9BK3qM_a5AM"
      },
      "id": "X9BK3qM_a5AM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TLDR :- Very high accuracy but also very high inference time, takes ~10 mins for 100 tests, will try to optimize"
      ],
      "metadata": {
        "id": "omxJPc0tbhGA"
      },
      "id": "omxJPc0tbhGA"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}